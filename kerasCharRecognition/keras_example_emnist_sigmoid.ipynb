{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USSV_OlCFKOD"
   },
   "source": [
    "# Training a neural network on MNIST with Keras\n",
    "\n",
    "This simple example demonstrates how to plug TensorFlow Datasets (TFDS) into a Keras model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8y9ZkLXmAZc"
   },
   "source": [
    "Copyright 2020 The TensorFlow Datasets Authors, Licensed under the Apache License, Version 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGw9EgE0tC0C"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/keras_example\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/keras_example.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/datasets/blob/master/docs/keras_example.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/datasets/docs/keras_example.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TTBSvHcSLBzc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:00:18.647052: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-18 17:00:18.647156: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/tim/Dokumente/Projects/jupyterLab/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjI6VgOBf0v0"
   },
   "source": [
    "## Step 1: Create your input pipeline\n",
    "\n",
    "Start by building an efficient input pipeline using advices from:\n",
    "* The [Performance tips](https://www.tensorflow.org/datasets/performances) guide\n",
    "* The [Better performance with the `tf.data` API](https://www.tensorflow.org/guide/data_performance#optimize_performance) guide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3aH3vP_XLI8"
   },
   "source": [
    "### Load a dataset\n",
    "\n",
    "Load the MNIST dataset with the following arguments:\n",
    "\n",
    "* `shuffle_files=True`: The MNIST data is only stored in a single file, but for larger datasets with multiple files on disk, it's good practice to shuffle them when training.\n",
    "* `as_supervised=True`: Returns a tuple `(img, label)` instead of a dictionary `{'image': img, 'label': label}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZUMhCXhFXdHQ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:00:27.520835: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-18 17:00:27.526494: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-18 17:00:27.526621: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (VirtDebian): /proc/driver/nvidia/version does not exist\n",
      "2022-08-18 17:00:27.533277: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'emnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgwCFAcWXQTx"
   },
   "source": [
    "### Build a training pipeline\n",
    "\n",
    "Apply the following transformations:\n",
    "\n",
    "* `tf.data.Dataset.map`: TFDS provide images of type `tf.uint8`, while the model expects `tf.float32`. Therefore, you need to normalize images.\n",
    "* `tf.data.Dataset.cache` As you fit the dataset in memory, cache it before shuffling for a better performance.<br/>\n",
    "__Note:__ Random transformations should be applied after caching.\n",
    "* `tf.data.Dataset.shuffle`: For true randomness, set the shuffle buffer to the full dataset size.<br/>\n",
    "__Note:__ For large datasets that can't fit in memory, use `buffer_size=1000` if your system allows it.\n",
    "* `tf.data.Dataset.batch`: Batch elements of the dataset after shuffling to get unique batches at each epoch.\n",
    "* `tf.data.Dataset.prefetch`: It is good practice to end the pipeline by prefetching [for performance](https://www.tensorflow.org/guide/data_performance#prefetching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "haykx2K9XgiI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbsMy4X1XVFv"
   },
   "source": [
    "### Build an evaluation pipeline\n",
    "\n",
    "Your testing pipeline is similar to the training pipeline with small differences:\n",
    "\n",
    " * You don't need to call `tf.data.Dataset.shuffle`.\n",
    " * Caching is done after batching because batches can be the same between epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A0KjuDf7XiqY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:00:53.452612: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 15752 of 697932\n",
      "2022-08-18 17:01:03.456031: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 34462 of 697932\n",
      "2022-08-18 17:01:13.452395: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 51098 of 697932\n",
      "2022-08-18 17:01:23.452873: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 68724 of 697932\n",
      "2022-08-18 17:01:33.452400: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 86022 of 697932\n",
      "2022-08-18 17:01:43.454166: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 102312 of 697932\n",
      "2022-08-18 17:01:53.452961: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 118651 of 697932\n",
      "2022-08-18 17:02:03.452643: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 135173 of 697932\n",
      "2022-08-18 17:02:13.453408: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 151661 of 697932\n",
      "2022-08-18 17:02:23.454165: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 167829 of 697932\n",
      "2022-08-18 17:02:33.453065: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 183759 of 697932\n",
      "2022-08-18 17:02:43.453762: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 200278 of 697932\n",
      "2022-08-18 17:02:53.452531: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 220450 of 697932\n",
      "2022-08-18 17:03:03.452355: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 242909 of 697932\n",
      "2022-08-18 17:03:13.452397: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 263056 of 697932\n",
      "2022-08-18 17:03:23.452809: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 285759 of 697932\n",
      "2022-08-18 17:03:33.453075: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 307743 of 697932\n",
      "2022-08-18 17:03:43.452647: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 329791 of 697932\n",
      "2022-08-18 17:03:53.453197: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 348410 of 697932\n",
      "2022-08-18 17:04:03.452477: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 364686 of 697932\n",
      "2022-08-18 17:04:13.452870: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 380535 of 697932\n",
      "2022-08-18 17:04:23.452526: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 396187 of 697932\n",
      "2022-08-18 17:04:33.452565: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 410881 of 697932\n",
      "2022-08-18 17:04:43.452739: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 425973 of 697932\n",
      "2022-08-18 17:04:53.453873: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 440874 of 697932\n",
      "2022-08-18 17:05:03.452987: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 455627 of 697932\n",
      "2022-08-18 17:05:13.454024: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 471912 of 697932\n",
      "2022-08-18 17:05:23.454002: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 492399 of 697932\n",
      "2022-08-18 17:05:33.453190: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 512847 of 697932\n",
      "2022-08-18 17:05:43.460147: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 533619 of 697932\n",
      "2022-08-18 17:05:53.452516: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 554265 of 697932\n",
      "2022-08-18 17:06:03.452848: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 575103 of 697932\n",
      "2022-08-18 17:06:13.452710: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 593295 of 697932\n",
      "2022-08-18 17:06:23.454285: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 608831 of 697932\n",
      "2022-08-18 17:06:33.452612: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 625786 of 697932\n",
      "2022-08-18 17:06:43.452543: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 642698 of 697932\n",
      "2022-08-18 17:06:53.457982: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 659354 of 697932\n",
      "2022-08-18 17:07:03.452668: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 675777 of 697932\n",
      "2022-08-18 17:07:13.461678: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 692891 of 697932\n",
      "2022-08-18 17:07:16.471729: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "(28, 28, 1)\n",
      "(128,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 F\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "charList = ['0','1','2','3','4','5','6','7','8','9',\n",
    "'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
    "'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "\n",
    "#print(ds_train.inspect)\n",
    "#dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "for element in ds_train:\n",
    "    #print(element)\n",
    "    break\n",
    "for element in ds_train.as_numpy_iterator():\n",
    "    print(type(element))\n",
    "    element1, element2 = element\n",
    "    print(element1[0].shape)\n",
    "    print(element2.shape)\n",
    "    plt.imshow(element1[0], cmap='gray') #Bilder sind gedreht und gespiegelt\n",
    "    plt.show()\n",
    "    print(element2[0], charList[element2[0]])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTFoji3INMEM"
   },
   "source": [
    "## Step 2: Create and train the model\n",
    "\n",
    "Plug the TFDS input pipeline into a simple Keras model, compile the model, and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XWqxdmS1NLKA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5452/5453 [============================>.] - ETA: 0s - loss: 0.7806 - sparse_categorical_accuracy: 0.7672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:11:21.772456: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfKerasCharsEMNISTSigmoid/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfKerasCharsEMNISTSigmoid/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5453/5453 [==============================] - 122s 22ms/step - loss: 0.7806 - sparse_categorical_accuracy: 0.7672 - val_loss: 0.5992 - val_sparse_categorical_accuracy: 0.8095\n",
      "Epoch 2/30\n",
      "5449/5453 [============================>.] - ETA: 0s - loss: 0.5734 - sparse_categorical_accuracy: 0.8164INFO:tensorflow:Assets written to: tfKerasCharsEMNISTSigmoid/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfKerasCharsEMNISTSigmoid/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5453/5453 [==============================] - 94s 17ms/step - loss: 0.5734 - sparse_categorical_accuracy: 0.8164 - val_loss: 0.5591 - val_sparse_categorical_accuracy: 0.8206\n",
      "Epoch 3/30\n",
      "5453/5453 [==============================] - 86s 15ms/step - loss: 0.5497 - sparse_categorical_accuracy: 0.8226 - val_loss: 0.5746 - val_sparse_categorical_accuracy: 0.8201\n",
      "Epoch 4/30\n",
      "5453/5453 [==============================] - 93s 17ms/step - loss: 0.5437 - sparse_categorical_accuracy: 0.8250 - val_loss: 0.5667 - val_sparse_categorical_accuracy: 0.8203\n",
      "Epoch 5/30\n",
      "5453/5453 [==============================] - 96s 17ms/step - loss: 0.5438 - sparse_categorical_accuracy: 0.8253 - val_loss: 0.5646 - val_sparse_categorical_accuracy: 0.8220\n",
      "Epoch 6/30\n",
      "5453/5453 [==============================] - 88s 16ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.8248 - val_loss: 0.5811 - val_sparse_categorical_accuracy: 0.8168\n",
      "Epoch 7/30\n",
      "5453/5453 [==============================] - 85s 15ms/step - loss: 0.5549 - sparse_categorical_accuracy: 0.8238 - val_loss: 0.5939 - val_sparse_categorical_accuracy: 0.8182\n",
      "Epoch 8/30\n",
      "5453/5453 [==============================] - 87s 16ms/step - loss: 0.5621 - sparse_categorical_accuracy: 0.8227 - val_loss: 0.6199 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 9/30\n",
      "5453/5453 [==============================] - 92s 17ms/step - loss: 0.5689 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.6225 - val_sparse_categorical_accuracy: 0.8150\n",
      "Epoch 10/30\n",
      "5453/5453 [==============================] - 86s 15ms/step - loss: 0.5760 - sparse_categorical_accuracy: 0.8205 - val_loss: 0.6224 - val_sparse_categorical_accuracy: 0.8135\n",
      "Epoch 11/30\n",
      "5453/5453 [==============================] - 92s 16ms/step - loss: 0.5828 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.6405 - val_sparse_categorical_accuracy: 0.8113\n",
      "Epoch 12/30\n",
      "5453/5453 [==============================] - 80s 14ms/step - loss: 0.5892 - sparse_categorical_accuracy: 0.8179 - val_loss: 0.6587 - val_sparse_categorical_accuracy: 0.8151\n",
      "Epoch 13/30\n",
      "5453/5453 [==============================] - 75s 13ms/step - loss: 0.5958 - sparse_categorical_accuracy: 0.8174 - val_loss: 0.6566 - val_sparse_categorical_accuracy: 0.8040\n",
      "Epoch 14/30\n",
      "5453/5453 [==============================] - 68s 12ms/step - loss: 0.6034 - sparse_categorical_accuracy: 0.8160 - val_loss: 0.6627 - val_sparse_categorical_accuracy: 0.8068\n",
      "Epoch 15/30\n",
      "5453/5453 [==============================] - 68s 12ms/step - loss: 0.6096 - sparse_categorical_accuracy: 0.8150 - val_loss: 0.6911 - val_sparse_categorical_accuracy: 0.8029\n",
      "Epoch 16/30\n",
      "5453/5453 [==============================] - 64s 12ms/step - loss: 0.6142 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.6854 - val_sparse_categorical_accuracy: 0.8018\n",
      "Epoch 17/30\n",
      "5453/5453 [==============================] - 61s 11ms/step - loss: 0.6204 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.7054 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 18/30\n",
      "5453/5453 [==============================] - 61s 11ms/step - loss: 0.6259 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.7054 - val_sparse_categorical_accuracy: 0.8086\n",
      "Epoch 19/30\n",
      "5453/5453 [==============================] - 61s 11ms/step - loss: 0.6335 - sparse_categorical_accuracy: 0.8116 - val_loss: 0.7622 - val_sparse_categorical_accuracy: 0.7776\n",
      "Epoch 20/30\n",
      "5453/5453 [==============================] - 60s 11ms/step - loss: 0.6395 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.7260 - val_sparse_categorical_accuracy: 0.8016\n",
      "Epoch 21/30\n",
      "5453/5453 [==============================] - 60s 11ms/step - loss: 0.6454 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.7376 - val_sparse_categorical_accuracy: 0.7956\n",
      "Epoch 22/30\n",
      "5453/5453 [==============================] - 71s 13ms/step - loss: 0.6504 - sparse_categorical_accuracy: 0.8098 - val_loss: 0.7474 - val_sparse_categorical_accuracy: 0.7935\n",
      "Epoch 23/30\n",
      "5453/5453 [==============================] - 73s 13ms/step - loss: 0.6556 - sparse_categorical_accuracy: 0.8085 - val_loss: 0.7525 - val_sparse_categorical_accuracy: 0.7994\n",
      "Epoch 24/30\n",
      "5453/5453 [==============================] - 74s 13ms/step - loss: 0.6615 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.7386 - val_sparse_categorical_accuracy: 0.7974\n",
      "Epoch 25/30\n",
      "5453/5453 [==============================] - 72s 13ms/step - loss: 0.6670 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.7597 - val_sparse_categorical_accuracy: 0.8020\n",
      "Epoch 26/30\n",
      "5453/5453 [==============================] - 74s 13ms/step - loss: 0.6729 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.7698 - val_sparse_categorical_accuracy: 0.7954\n",
      "Epoch 27/30\n",
      "5453/5453 [==============================] - 69s 12ms/step - loss: 0.6782 - sparse_categorical_accuracy: 0.8053 - val_loss: 0.7833 - val_sparse_categorical_accuracy: 0.7980\n",
      "Epoch 28/30\n",
      "5453/5453 [==============================] - 72s 13ms/step - loss: 0.6812 - sparse_categorical_accuracy: 0.8048 - val_loss: 0.7851 - val_sparse_categorical_accuracy: 0.7898\n",
      "Epoch 29/30\n",
      "5453/5453 [==============================] - 71s 13ms/step - loss: 0.6859 - sparse_categorical_accuracy: 0.8045 - val_loss: 0.7802 - val_sparse_categorical_accuracy: 0.7967\n",
      "Epoch 30/30\n",
      "5453/5453 [==============================] - 74s 13ms/step - loss: 0.6907 - sparse_categorical_accuracy: 0.8041 - val_loss: 0.8091 - val_sparse_categorical_accuracy: 0.7873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3496b9550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(62, \"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(),\n",
    "    #optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=30,\n",
    "    validation_data=ds_test,\n",
    "    callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath='tfKerasCharsEMNISTSigmoid', save_best_only=True, monitor=\"val_loss\"),\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:55:26.548270: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-08-18 17:55:26.548336: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "2022-08-18 17:55:26.549246: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: tfKerasCharsEMNISTSigmoid\n",
      "2022-08-18 17:55:26.550519: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-08-18 17:55:26.550560: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: tfKerasCharsEMNISTSigmoid\n",
      "2022-08-18 17:55:26.555152: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-08-18 17:55:26.629378: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: tfKerasCharsEMNISTSigmoid\n",
      "2022-08-18 17:55:26.655962: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 106716 microseconds.\n",
      "2022-08-18 17:55:26.683187: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('tfKerasCharsEMNISTSigmoid')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"tfKerasCharsEMNISTSigmoid.tflite\", \"wb\") as fp:\n",
    "    fp.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,478\n",
      "Trainable params: 108,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Element1 Shape (28, 28, 1)\n",
      "Ergebnis Shape (1, 62)\n",
      "Zeichen unmapped 0 Zeichen mapped 0 Ergebnis 5.089538e-07\n",
      "Element 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "charList = ['0','1','2','3','4','5','6','7','8','9',\n",
    "'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
    "'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "model = tf.keras.models.load_model('tfKerasCharsEMNISTSigmoid')\n",
    "model.summary()\n",
    "\n",
    "for element in ds_train.as_numpy_iterator():\n",
    "    element1, element2 = element\n",
    "    ele = np.resize(element1[0],(1,28,28,1))\n",
    "    erg = model.predict(ele)\n",
    "    print(\"Element1 Shape\", element1[0].shape)\n",
    "    print(\"Ergebnis Shape\", erg.shape)\n",
    "    print(\"Zeichen unmapped\", np.argmax(erg), \"Zeichen mapped\", charList[np.argmax(erg)], \"Ergebnis\", erg[0][np.argmax(erg)])\n",
    "    print(\"Element\", element2[0])\n",
    "    plt.imshow(element1[0], cmap='gray') #Bilder sind gedreht und gespiegelt\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 62)                7998      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,478\n",
      "Trainable params: 108,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(1, 28, 28)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('tfKerasCharsEMNISTSigmoid')\n",
    "model.summary()\n",
    "\n",
    "data = np.random.randint(0, 255, (1, 28, 28))/255\n",
    "\n",
    "print(data.shape)\n",
    "#print(data[1][1])\n",
    "\n",
    "erg = model.predict(data)\n",
    "#print(np.argmax(erg))\n",
    "print(erg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"tfKerasCharsEMNISTSigmoid.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], data.astype(np.float32))\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tensorflow/datasets",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
