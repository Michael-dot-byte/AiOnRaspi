{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USSV_OlCFKOD"
   },
   "source": [
    "# Training a neural network on MNIST with Keras\n",
    "\n",
    "This simple example demonstrates how to plug TensorFlow Datasets (TFDS) into a Keras model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8y9ZkLXmAZc"
   },
   "source": [
    "Copyright 2020 The TensorFlow Datasets Authors, Licensed under the Apache License, Version 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGw9EgE0tC0C"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/datasets/keras_example\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/keras_example.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/datasets/blob/master/docs/keras_example.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/datasets/docs/keras_example.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TTBSvHcSLBzc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 07:51:20.991301: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-17 07:51:20.991346: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/tim/Dokumente/Projects/jupyterLab/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjI6VgOBf0v0"
   },
   "source": [
    "## Step 1: Create your input pipeline\n",
    "\n",
    "Start by building an efficient input pipeline using advices from:\n",
    "* The [Performance tips](https://www.tensorflow.org/datasets/performances) guide\n",
    "* The [Better performance with the `tf.data` API](https://www.tensorflow.org/guide/data_performance#optimize_performance) guide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3aH3vP_XLI8"
   },
   "source": [
    "### Load a dataset\n",
    "\n",
    "Load the MNIST dataset with the following arguments:\n",
    "\n",
    "* `shuffle_files=True`: The MNIST data is only stored in a single file, but for larger datasets with multiple files on disk, it's good practice to shuffle them when training.\n",
    "* `as_supervised=True`: Returns a tuple `(img, label)` instead of a dictionary `{'image': img, 'label': label}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZUMhCXhFXdHQ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 07:51:32.518255: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-17 07:51:32.518283: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-17 07:51:32.518304: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (VirtDebian): /proc/driver/nvidia/version does not exist\n",
      "2022-08-17 07:51:32.520281: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'emnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgwCFAcWXQTx"
   },
   "source": [
    "### Build a training pipeline\n",
    "\n",
    "Apply the following transformations:\n",
    "\n",
    "* `tf.data.Dataset.map`: TFDS provide images of type `tf.uint8`, while the model expects `tf.float32`. Therefore, you need to normalize images.\n",
    "* `tf.data.Dataset.cache` As you fit the dataset in memory, cache it before shuffling for a better performance.<br/>\n",
    "__Note:__ Random transformations should be applied after caching.\n",
    "* `tf.data.Dataset.shuffle`: For true randomness, set the shuffle buffer to the full dataset size.<br/>\n",
    "__Note:__ For large datasets that can't fit in memory, use `buffer_size=1000` if your system allows it.\n",
    "* `tf.data.Dataset.batch`: Batch elements of the dataset after shuffling to get unique batches at each epoch.\n",
    "* `tf.data.Dataset.prefetch`: It is good practice to end the pipeline by prefetching [for performance](https://www.tensorflow.org/guide/data_performance#prefetching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "haykx2K9XgiI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbsMy4X1XVFv"
   },
   "source": [
    "### Build an evaluation pipeline\n",
    "\n",
    "Your testing pipeline is similar to the training pipeline with small differences:\n",
    "\n",
    " * You don't need to call `tf.data.Dataset.shuffle`.\n",
    " * Caching is done after batching because batches can be the same between epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A0KjuDf7XiqY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 14:43:45.669136: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 8150 of 697932\n",
      "2022-08-16 14:43:55.673975: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 17522 of 697932\n",
      "2022-08-16 14:44:05.668659: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 27852 of 697932\n",
      "2022-08-16 14:44:15.668449: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 38526 of 697932\n",
      "2022-08-16 14:44:25.669922: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 47747 of 697932\n",
      "2022-08-16 14:44:35.668729: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 55031 of 697932\n",
      "2022-08-16 14:44:45.670351: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 63507 of 697932\n",
      "2022-08-16 14:44:55.668552: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 72571 of 697932\n",
      "2022-08-16 14:45:05.669115: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 80516 of 697932\n",
      "2022-08-16 14:45:15.668491: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 89950 of 697932\n",
      "2022-08-16 14:45:25.668542: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 100130 of 697932\n",
      "2022-08-16 14:45:35.668828: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 109521 of 697932\n",
      "2022-08-16 14:45:45.670191: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 119827 of 697932\n",
      "2022-08-16 14:45:55.668678: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 129663 of 697932\n",
      "2022-08-16 14:46:05.670076: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 139249 of 697932\n",
      "2022-08-16 14:46:15.668185: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 149725 of 697932\n",
      "2022-08-16 14:46:25.669652: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 160555 of 697932\n",
      "2022-08-16 14:46:35.668885: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 171009 of 697932\n",
      "2022-08-16 14:46:45.668801: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 181484 of 697932\n",
      "2022-08-16 14:46:55.668824: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 191718 of 697932\n",
      "2022-08-16 14:47:05.669087: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 201391 of 697932\n",
      "2022-08-16 14:47:15.668408: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 211721 of 697932\n",
      "2022-08-16 14:47:25.668444: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 222361 of 697932\n",
      "2022-08-16 14:47:35.669079: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 232090 of 697932\n",
      "2022-08-16 14:47:45.670461: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 242494 of 697932\n",
      "2022-08-16 14:47:55.669066: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 251404 of 697932\n",
      "2022-08-16 14:48:05.669150: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 261419 of 697932\n",
      "2022-08-16 14:48:15.669071: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 271969 of 697932\n",
      "2022-08-16 14:48:25.669627: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 281418 of 697932\n",
      "2022-08-16 14:48:35.669079: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 289366 of 697932\n",
      "2022-08-16 14:48:45.670489: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 297945 of 697932\n",
      "2022-08-16 14:48:55.671988: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 306586 of 697932\n",
      "2022-08-16 14:49:05.669062: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 314931 of 697932\n",
      "2022-08-16 14:49:15.669009: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 324709 of 697932\n",
      "2022-08-16 14:49:25.669184: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 334824 of 697932\n",
      "2022-08-16 14:49:35.669622: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 344362 of 697932\n",
      "2022-08-16 14:49:45.671198: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 352563 of 697932\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "charList = ['0','1','2','3','4','5','6','7','8','9',\n",
    "'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
    "'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "\n",
    "#print(ds_train.inspect)\n",
    "#dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "for element in ds_train:\n",
    "    #print(element)\n",
    "    break\n",
    "for element in ds_train.as_numpy_iterator():\n",
    "    print(type(element))\n",
    "    element1, element2 = element\n",
    "    print(element1[0].shape)\n",
    "    print(element2.shape)\n",
    "    plt.imshow(element1[0], cmap='gray') #Bilder sind gedreht und gespiegelt\n",
    "    plt.show()\n",
    "    print(element2[0], charList[element2[0]])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTFoji3INMEM"
   },
   "source": [
    "## Step 2: Create and train the model\n",
    "\n",
    "Plug the TFDS input pipeline into a simple Keras model, compile the model, and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XWqxdmS1NLKA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 07:52:11.641689: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 54453 of 697932\n",
      "2022-08-17 07:52:21.641700: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 116052 of 697932\n",
      "2022-08-17 07:52:31.641708: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 176480 of 697932\n",
      "2022-08-17 07:52:41.641712: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 237656 of 697932\n",
      "2022-08-17 07:52:51.641625: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 298664 of 697932\n",
      "2022-08-17 07:53:01.641989: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 359306 of 697932\n",
      "2022-08-17 07:53:11.641727: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 421665 of 697932\n",
      "2022-08-17 07:53:21.642007: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 480937 of 697932\n",
      "2022-08-17 07:53:31.641883: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 540859 of 697932\n",
      "2022-08-17 07:53:41.643034: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 603686 of 697932\n",
      "2022-08-17 07:53:51.641894: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 667439 of 697932\n",
      "2022-08-17 07:53:56.419589: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5453/5453 [==============================] - ETA: 0s - loss: 0.5918 - sparse_categorical_accuracy: 0.8107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 08:04:22.543309: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfKerasCharsExternalExample/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfKerasCharsExternalExample/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5453/5453 [==============================] - 742s 115ms/step - loss: 0.5918 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.4495 - val_sparse_categorical_accuracy: 0.8448\n",
      "Epoch 2/30\n",
      "5453/5453 [==============================] - ETA: 0s - loss: 0.5136 - sparse_categorical_accuracy: 0.8329INFO:tensorflow:Assets written to: tfKerasCharsExternalExample/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfKerasCharsExternalExample/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5453/5453 [==============================] - 633s 116ms/step - loss: 0.5136 - sparse_categorical_accuracy: 0.8329 - val_loss: 0.4356 - val_sparse_categorical_accuracy: 0.8500\n",
      "Epoch 3/30\n",
      "5453/5453 [==============================] - 675s 124ms/step - loss: 0.5218 - sparse_categorical_accuracy: 0.8327 - val_loss: 0.5847 - val_sparse_categorical_accuracy: 0.8400\n",
      "Epoch 4/30\n",
      "5453/5453 [==============================] - 664s 122ms/step - loss: 0.5362 - sparse_categorical_accuracy: 0.8311 - val_loss: 0.5270 - val_sparse_categorical_accuracy: 0.8439\n",
      "Epoch 5/30\n",
      "5453/5453 [==============================] - 641s 117ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.8295 - val_loss: 0.4805 - val_sparse_categorical_accuracy: 0.8413\n",
      "Epoch 6/30\n",
      "5453/5453 [==============================] - 647s 119ms/step - loss: 0.5572 - sparse_categorical_accuracy: 0.8275 - val_loss: 0.4529 - val_sparse_categorical_accuracy: 0.8479\n",
      "Epoch 7/30\n",
      "5453/5453 [==============================] - 630s 115ms/step - loss: 0.5726 - sparse_categorical_accuracy: 0.8256 - val_loss: 0.4649 - val_sparse_categorical_accuracy: 0.8466\n",
      "Epoch 8/30\n",
      "5453/5453 [==============================] - 637s 117ms/step - loss: 0.5795 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.7035 - val_sparse_categorical_accuracy: 0.8334\n",
      "Epoch 9/30\n",
      "5453/5453 [==============================] - 650s 119ms/step - loss: 0.5887 - sparse_categorical_accuracy: 0.8214 - val_loss: 0.6079 - val_sparse_categorical_accuracy: 0.8244\n",
      "Epoch 10/30\n",
      "5453/5453 [==============================] - 713s 131ms/step - loss: 0.5990 - sparse_categorical_accuracy: 0.8189 - val_loss: 0.4722 - val_sparse_categorical_accuracy: 0.8454\n",
      "Epoch 11/30\n",
      "5453/5453 [==============================] - 681s 125ms/step - loss: 0.6088 - sparse_categorical_accuracy: 0.8167 - val_loss: 0.4819 - val_sparse_categorical_accuracy: 0.8389\n",
      "Epoch 12/30\n",
      "5453/5453 [==============================] - 644s 118ms/step - loss: 0.6216 - sparse_categorical_accuracy: 0.8149 - val_loss: 0.5051 - val_sparse_categorical_accuracy: 0.8451\n",
      "Epoch 13/30\n",
      "5453/5453 [==============================] - 639s 117ms/step - loss: 0.6299 - sparse_categorical_accuracy: 0.8132 - val_loss: 0.7692 - val_sparse_categorical_accuracy: 0.8390\n",
      "Epoch 14/30\n",
      "5453/5453 [==============================] - 643s 118ms/step - loss: 0.6429 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.8352\n",
      "Epoch 15/30\n",
      "5453/5453 [==============================] - 662s 121ms/step - loss: 0.6447 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.4948 - val_sparse_categorical_accuracy: 0.8390\n",
      "Epoch 16/30\n",
      "5453/5453 [==============================] - 697s 128ms/step - loss: 0.6544 - sparse_categorical_accuracy: 0.8075 - val_loss: 0.5543 - val_sparse_categorical_accuracy: 0.8214\n",
      "Epoch 17/30\n",
      "5453/5453 [==============================] - 694s 127ms/step - loss: 0.6626 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.4994 - val_sparse_categorical_accuracy: 0.8428\n",
      "Epoch 18/30\n",
      "5453/5453 [==============================] - 704s 129ms/step - loss: 0.6712 - sparse_categorical_accuracy: 0.8044 - val_loss: 0.5022 - val_sparse_categorical_accuracy: 0.8374\n",
      "Epoch 19/30\n",
      "5453/5453 [==============================] - 691s 127ms/step - loss: 0.6816 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.5015 - val_sparse_categorical_accuracy: 0.8348\n",
      "Epoch 20/30\n",
      "5453/5453 [==============================] - 651s 119ms/step - loss: 0.6892 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.5076 - val_sparse_categorical_accuracy: 0.8339\n",
      "Epoch 21/30\n",
      "5453/5453 [==============================] - 646s 118ms/step - loss: 0.6977 - sparse_categorical_accuracy: 0.7991 - val_loss: 0.5244 - val_sparse_categorical_accuracy: 0.8297\n",
      "Epoch 22/30\n",
      "5453/5453 [==============================] - 636s 117ms/step - loss: 0.7099 - sparse_categorical_accuracy: 0.7983 - val_loss: 0.5107 - val_sparse_categorical_accuracy: 0.8330\n",
      "Epoch 23/30\n",
      "5453/5453 [==============================] - 631s 116ms/step - loss: 0.7333 - sparse_categorical_accuracy: 0.7968 - val_loss: 0.5756 - val_sparse_categorical_accuracy: 0.8267\n",
      "Epoch 24/30\n",
      "5453/5453 [==============================] - 628s 115ms/step - loss: 0.7225 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.5720 - val_sparse_categorical_accuracy: 0.8367\n",
      "Epoch 25/30\n",
      "5453/5453 [==============================] - 632s 116ms/step - loss: 0.7305 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.7112 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 26/30\n",
      "5453/5453 [==============================] - 655s 120ms/step - loss: 0.7414 - sparse_categorical_accuracy: 0.7915 - val_loss: 0.5271 - val_sparse_categorical_accuracy: 0.8343\n",
      "Epoch 27/30\n",
      "5453/5453 [==============================] - 695s 127ms/step - loss: 0.7434 - sparse_categorical_accuracy: 0.7903 - val_loss: 1.0197 - val_sparse_categorical_accuracy: 0.8329\n",
      "Epoch 28/30\n",
      "5453/5453 [==============================] - 678s 124ms/step - loss: 0.7583 - sparse_categorical_accuracy: 0.7886 - val_loss: 0.5165 - val_sparse_categorical_accuracy: 0.8296\n",
      "Epoch 29/30\n",
      "5453/5453 [==============================] - 660s 121ms/step - loss: 0.7656 - sparse_categorical_accuracy: 0.7881 - val_loss: 0.6510 - val_sparse_categorical_accuracy: 0.8379\n",
      "Epoch 30/30\n",
      "5453/5453 [==============================] - 664s 122ms/step - loss: 0.7659 - sparse_categorical_accuracy: 0.7864 - val_loss: 0.5369 - val_sparse_categorical_accuracy: 0.8260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f47b451b8b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = tf.keras.models.Sequential([\n",
    "#  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#  tf.keras.layers.Dense(62, \"sigmoid\")\n",
    "#  #tf.keras.layers.Dense(62)\n",
    "#])\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Convolution2D, Dropout, Dense, Flatten, LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "nb_classes = 62\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "nb_filters = 32 # number of convolutional filters to use\n",
    "pool_size = (2, 2) # size of pooling area for max pooling\n",
    "kernel_size = (3, 3) # convolution kernel size\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, kernel_size, padding='valid', input_shape=input_shape, activation='relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size, activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(),\n",
    "    #optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=30,\n",
    "    validation_data=ds_test,\n",
    "    callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath='tfKerasCharsExternalExample', save_best_only=True, monitor=\"val_loss\"),\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('tfKerasCharsExternalExample')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"tfKerasCharsExternalExample.tflite\", \"wb\") as fp:\n",
    "    fp.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "charList = ['0','1','2','3','4','5','6','7','8','9',\n",
    "'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
    "'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "model = tf.keras.models.load_model('tfKerasCharsExternalExample')\n",
    "model.summary()\n",
    "\n",
    "for element in ds_train.as_numpy_iterator():\n",
    "    element1, element2 = element\n",
    "    ele = np.resize(element1[0],(1,28,28,1))\n",
    "    erg = model.predict(ele)\n",
    "    print(\"Element1 Shape\", element1[0].shape)\n",
    "    print(\"Ergebnis Shape\", erg.shape)\n",
    "    print(\"Zeichen unmapped\", np.argmax(erg), \"Zeichen mapped\", charList[np.argmax(erg)], \"Ergebnis\", erg[0][np.argmax(erg)])\n",
    "    print(\"Element\", element2[0])\n",
    "    plt.imshow(element1[0], cmap='gray') #Bilder sind gedreht und gespiegelt\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('tfKerasCharsExternalExample')\n",
    "model.summary()\n",
    "\n",
    "data = np.random.randint(0, 255, (1, 28, 28))/255\n",
    "\n",
    "print(data.shape)\n",
    "#print(data[1][1])\n",
    "\n",
    "erg = model.predict(data)\n",
    "#print(np.argmax(erg))\n",
    "print(erg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"tfKerasCharsExternalExample.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], data.astype(np.float32))\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tensorflow/datasets",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
